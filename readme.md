# ğŸ—ï¸ Lakehouse Project

> Plataforma completa de Data Lakehouse com orquestraÃ§Ã£o Apache Airflow, streaming Kafka, armazenamento MinIO, processamento Dremio e monitoramento integrado com Prometheus/Grafana.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Tecnologias](#-tecnologias)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [ServiÃ§os e Portas](#-serviÃ§os-e-portas)
- [Uso](#-uso)
- [Camadas do Lakehouse](#-camadas-do-lakehouse)
- [Monitoramento](#-monitoramento)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Troubleshooting](#-troubleshooting)
- [ManutenÃ§Ã£o](#-manutenÃ§Ã£o)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa uma arquitetura moderna de **Data Lakehouse** combinando as melhores prÃ¡ticas de Data Lake e Data Warehouse. A plataforma oferece:

- **OrquestraÃ§Ã£o de Pipelines**: Apache Airflow com CeleryExecutor e workers dedicados por camada
- **IngestÃ£o de Dados em Tempo Real**: Apache Kafka para streaming
- **Armazenamento Object Storage**: MinIO compatÃ­vel com S3
- **Processamento AnalÃ­tico**: Dremio para query engine
- **Armazenamento Estruturado**: PostgreSQL, MongoDB, Cassandra
- **Monitoramento Completo**: Prometheus, Grafana, Loki, Promtail
- **Observabilidade**: cAdvisor para mÃ©tricas de containers, exporters para databases

### Arquitetura em Camadas (Medallion)

O projeto segue o padrÃ£o **Medallion Architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bronze    â”‚â”€â”€â”€â–¶â”‚   Silver    â”‚â”€â”€â”€â–¶â”‚    Gold     â”‚
â”‚  (Raw Data) â”‚    â”‚ (Cleaned)   â”‚    â”‚ (Aggregated)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â–²                  â–²                   â–²
      â”‚                  â”‚                   â”‚
  Worker Bronze     Worker Silver      Worker Gold
```

---

## ğŸ›ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MONITORING LAYER                          â”‚
â”‚  Prometheus â”‚ Grafana â”‚ Loki â”‚ Promtail â”‚ cAdvisor          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATION LAYER                         â”‚
â”‚  Airflow Webserver â”‚ Scheduler â”‚ Workers (Bronze/Silver/Gold)â”‚
â”‚  Redis (Broker) â”‚ PostgreSQL (Metadata)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING LAYER                          â”‚
â”‚  Dremio (Query Engine) â”‚ Kafka (Streaming)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STORAGE LAYER                             â”‚
â”‚  MinIO (Object Storage) â”‚ MongoDB â”‚ Cassandra â”‚ PostgreSQL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tecnologias

### OrquestraÃ§Ã£o
- **Apache Airflow 2.9.1**: Orquestrador de workflows com DAGs Python
- **Celery**: Executor distribuÃ­do para processamento paralelo
- **Redis 7**: Message broker para Celery

### Processamento
- **Apache Kafka 7.5.0**: Plataforma de streaming de eventos
- **Dremio**: Query engine para data lakehouse
- **Zookeeper**: CoordenaÃ§Ã£o do Kafka cluster

### Armazenamento
- **MinIO**: Object storage compatÃ­vel com S3
- **PostgreSQL 15**: Banco relacional para metadados do Airflow
- **MongoDB**: Banco NoSQL orientado a documentos
- **Cassandra 4**: Banco NoSQL distribuÃ­do wide-column

### Monitoramento
- **Prometheus**: Sistema de monitoramento e alertas
- **Grafana**: VisualizaÃ§Ã£o de mÃ©tricas e logs
- **Loki**: AgregaÃ§Ã£o de logs
- **Promtail**: Agent de coleta de logs
- **cAdvisor**: MÃ©tricas de containers
- **Exporters**: MongoDB e Cassandra exporters

### UI & Ferramentas
- **Kafka UI**: Interface web para gerenciamento Kafka
- **Mongo Express**: Interface web para MongoDB
- **MinIO Console**: Interface web para object storage

---

## ğŸ“¦ PrÃ©-requisitos

- **Docker** 20.10+
- **Docker Compose** 2.0+
- **Git**
- **Sistema Operacional**: Windows, macOS ou Linux
- **Recursos MÃ­nimos**:
  - 8 GB RAM (recomendado 16 GB)
  - 20 GB espaÃ§o em disco
  - CPU com 4+ cores

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/BehindTheBush/lakehouse-project.git
cd lakehouse-project
```

### 2. ConfiguraÃ§Ã£o Inicial

A configuraÃ§Ã£o padrÃ£o jÃ¡ estÃ¡ pronta para uso. Se necessÃ¡rio, ajuste variÃ¡veis de ambiente no `docker-compose.yml`.

### 3. Build e Deploy

```bash
# Build das imagens customizadas
docker-compose build

# Subir todos os serviÃ§os
docker-compose up -d

# Acompanhar logs (opcional)
docker-compose logs -f
```

### 4. Verificar Status

```bash
# Verificar containers rodando
docker-compose ps

# Verificar logs do Airflow init
docker-compose logs airflow-init

# Verificar saÃºde do PostgreSQL
docker-compose logs postgres
```

### 5. Acessar ServiÃ§os

Aguarde ~2 minutos para todos os serviÃ§os inicializarem completamente, entÃ£o acesse as interfaces web listadas abaixo.

---

## ğŸŒ ServiÃ§os e Portas

| ServiÃ§o           | URL/Host                                        | Credenciais              | DescriÃ§Ã£o                          |
|-------------------|-------------------------------------------------|--------------------------|------------------------------------|
| **Airflow**       | [http://localhost:8080](http://localhost:8080)  | admin / admin            | Orquestrador de workflows          |
| **Grafana**       | [http://localhost:3000](http://localhost:3000)  | admin / admin            | Dashboards e visualizaÃ§Ã£o          |
| **Prometheus**    | [http://localhost:9090](http://localhost:9090)  | â€”                        | MÃ©tricas e alertas                 |
| **MinIO Console** | [http://localhost:9001](http://localhost:9001)  | minioadmin / minioadmin  | Object storage console             |
| **MinIO API**     | `localhost:9000`                                | minioadmin / minioadmin  | API S3-compatible                  |
| **Dremio**        | [http://localhost:9047](http://localhost:9047)  | admin / admin (1Âº acesso)| Query engine                       |
| **Kafka UI**      | [http://localhost:8082](http://localhost:8082)  | â€”                        | Interface Kafka                    |
| **Mongo Express** | [http://localhost:8081](http://localhost:8081)  | â€”                        | Interface MongoDB                  |
| **cAdvisor**      | [http://localhost:8083](http://localhost:8083)  | â€”                        | MÃ©tricas de containers             |
| **Loki**          | `http://localhost:3100`                         | â€”                        | API de logs                        |
| **PostgreSQL**    | `localhost:5432`                                | airflow / airflow        | Metadados Airflow                  |
| **MongoDB**       | `localhost:27017`                               | root / root              | Banco NoSQL                        |
| **Cassandra**     | `localhost:9042`                                | â€”                        | Banco distribuÃ­do                  |
| **Redis**         | `localhost:6379`                                | â€”                        | Celery broker                      |
| **Kafka**         | `localhost:9092`                                | â€”                        | Message broker                     |
| **Zookeeper**     | `localhost:2181`                                | â€”                        | Kafka coordinator                  |

---

## ğŸ’¼ Uso

### Gerenciamento de DAGs no Airflow

1. **Acessar Airflow**: http://localhost:8080
2. **Criar DAGs**: Adicionar arquivos `.py` em `dags/bronze/`, `dags/silver/` ou `dags/gold/`
3. **Filas de ExecuÃ§Ã£o**:
   - `bronze`: Workers para ingestÃ£o de dados brutos
   - `silver`: Workers para limpeza e transformaÃ§Ã£o
   - `gold`: Workers para agregaÃ§Ã£o e analytics

**Exemplo de DAG com fila especÃ­fica**:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

with DAG(
    'exemplo_bronze',
    start_date=datetime(2025, 1, 1),
    schedule_interval='@daily',
    catchup=False
) as dag:
    
    task = PythonOperator(
        task_id='ingest_data',
        python_callable=my_function,
        queue='bronze'  # Define a fila
    )
```

### Monitorar Pipelines

```bash
# Ver logs de um worker especÃ­fico
docker-compose logs -f airflow-worker-bronze-2

# Ver status do scheduler
docker-compose logs -f airflow-scheduler

# Ver tasks em execuÃ§Ã£o
docker exec airflow-webserver airflow tasks list <dag_id>
```

### Trabalhar com MinIO (Object Storage)

```python
from minio import Minio

client = Minio(
    "localhost:9000",
    access_key="minioadmin",
    secret_key="minioadmin",
    secure=False
)

# Criar bucket
client.make_bucket("bronze-data")

# Upload arquivo
client.fput_object("bronze-data", "file.csv", "/path/to/file.csv")
```

### Streaming com Kafka

```bash
# Produzir mensagens (exemplo)
docker exec -it kafka kafka-console-producer \
  --broker-list localhost:9092 \
  --topic twitter.filmes.raw.v1

# Consumir mensagens
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic twitter.filmes.raw.v1 \
  --from-beginning
```

---

## ğŸ… Camadas do Lakehouse

### Bronze (Raw)
- **PropÃ³sito**: IngestÃ£o de dados brutos sem transformaÃ§Ãµes
- **Worker**: `airflow-worker-bronze-2`
- **DAGs**: `dags/bronze/`
- **Exemplo**: `usuario_bronze.py`

### Silver (Cleaned)
- **PropÃ³sito**: Limpeza, validaÃ§Ã£o e enriquecimento
- **Worker**: `airflow-worker-silver-2`
- **DAGs**: `dags/silver/`
- **Exemplos**: `usuario_silver.py`, `acesso_banda_larga_silver.py`

### Gold (Analytics)
- **PropÃ³sito**: AgregaÃ§Ãµes e modelos analÃ­ticos
- **Worker**: `airflow-worker-gold-2`
- **DAGs**: `dags/gold/`
- **Exemplo**: `acesso_banda_larga_gold.py`

---

## ğŸ“Š Monitoramento

### Grafana Dashboards

O projeto inclui dashboard prÃ©-configurado: **Lakehouse Overview**

**Acesso**: http://localhost:3000 â†’ Dashboards â†’ Lakehouse Overview

**PainÃ©is disponÃ­veis**:
- âœ… Airflow service status
- ğŸ’» Container CPU usage
- ğŸ’¾ Container memory usage
- ğŸ¯ Prometheus targets health

### Prometheus Targets

**Acesso**: http://localhost:9090/targets

Targets monitorados:
- Prometheus (self-monitoring)
- cAdvisor (mÃ©tricas de containers)
- Airflow
- Kafka
- Redis
- Cassandra (via exporter)
- MongoDB (via exporter)

### Logs com Loki

Logs centralizados acessÃ­veis via Grafana:
1. Acessar Grafana â†’ Explore
2. Selecionar datasource **Loki**
3. Query exemplo: `{job="containerlogs"}`

### Alertas

Configure alertas no Grafana para:
- ServiÃ§os down
- Uso excessivo de CPU/memÃ³ria
- Falhas em DAGs do Airflow
- Atrasos em filas do Celery

---

## ğŸ“‚ Estrutura do Projeto

```
lakehouse-project/
â”œâ”€â”€ dags/                          # DAGs do Airflow
â”‚   â”œâ”€â”€ bronze/                    # IngestÃ£o de dados brutos
â”‚   â”‚   â””â”€â”€ usuario_bronze.py
â”‚   â”œâ”€â”€ silver/                    # TransformaÃ§Ã£o e limpeza
â”‚   â”‚   â”œâ”€â”€ usuario_silver.py
â”‚   â”‚   â””â”€â”€ acesso_banda_larga_silver.py
â”‚   â””â”€â”€ gold/                      # AgregaÃ§Ãµes analÃ­ticas
â”‚       â””â”€â”€ acesso_banda_larga_gold.py
â”‚
â”œâ”€â”€ infra/                         # Infraestrutura
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ Dockerfile             # Imagem customizada Airflow
â”‚   â”‚   â””â”€â”€ requirements.txt       # DependÃªncias Python
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â””â”€â”€ init-topics.sh         # CriaÃ§Ã£o de tÃ³picos
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ prometheus.yml         # Config Prometheus
â”‚       â”œâ”€â”€ loki-config.yaml       # Config Loki
â”‚       â”œâ”€â”€ promtail-config.yaml   # Config Promtail
â”‚       â””â”€â”€ grafana/
â”‚           â””â”€â”€ provisioning/
â”‚               â”œâ”€â”€ datasources/   # Datasources automÃ¡ticos
â”‚               â”‚   â””â”€â”€ datasources.yaml
â”‚               â””â”€â”€ dashboards/    # Dashboards provisionados
â”‚                   â”œâ”€â”€ dashboards.yaml
â”‚                   â””â”€â”€ lakehouse_overview.json
â”‚
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o completa
â””â”€â”€ readme.md                      # Este arquivo
```

---

## ğŸ”§ Troubleshooting

### Airflow nÃ£o inicia

```bash
# Verificar logs do postgres
docker-compose logs postgres

# Verificar logs do airflow-init
docker-compose logs airflow-init

# Resetar banco de dados (CUIDADO: apaga dados)
docker-compose down -v
docker-compose up -d
```

### Workers nÃ£o processam tasks

```bash
# Verificar se workers estÃ£o rodando
docker-compose ps | grep worker

# Verificar logs de um worker
docker-compose logs -f airflow-worker-bronze-2

# Verificar Redis
docker-compose logs redis

# Reiniciar workers
docker-compose restart airflow-worker-bronze-2 airflow-worker-silver-2 airflow-worker-gold-2
```

### Prometheus nÃ£o coleta mÃ©tricas

```bash
# Verificar configuraÃ§Ã£o
docker exec prometheus cat /etc/prometheus/prometheus.yml

# Verificar targets no navegador
# http://localhost:9090/targets

# Reiniciar Prometheus
docker-compose restart prometheus
```

### Grafana nÃ£o mostra dashboard

```bash
# Verificar provisionamento
docker exec grafana ls -la /etc/grafana/provisioning/dashboards/

# Verificar logs
docker-compose logs grafana | grep -i dashboard

# ForÃ§ar reload
docker-compose restart grafana
```

### Kafka nÃ£o recebe mensagens

```bash
# Verificar Zookeeper
docker-compose logs zookeeper

# Verificar Kafka
docker-compose logs kafka

# Listar tÃ³picos
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Descrever tÃ³pico
docker exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic twitter.filmes.raw.v1
```

### MinIO inacessÃ­vel

```bash
# Verificar logs
docker-compose logs minio

# Verificar volumes
docker volume ls | grep minio

# Reiniciar MinIO
docker-compose restart minio
```

### Containers com erro "Out of Memory"

```bash
# Verificar uso de memÃ³ria
docker stats

# Aumentar recursos no Docker Desktop:
# Settings â†’ Resources â†’ Memory â†’ 8GB+

# Parar serviÃ§os nÃ£o essenciais temporariamente
docker-compose stop mongo mongo-express
```

### Portas jÃ¡ em uso

```bash
# Windows: Verificar porta ocupada
netstat -ano | findstr :8080

# Matar processo (PowerShell como Admin)
Stop-Process -Id <PID> -Force

# Ou alterar porta no docker-compose.yml
# Exemplo: - "8081:8080"  # ExpÃµe na porta 8081
```

---

## ğŸ”„ ManutenÃ§Ã£o

### Backup de Dados

```bash
# Backup PostgreSQL
docker exec postgres pg_dump -U airflow airflow > backup_airflow.sql

# Backup MongoDB
docker exec mongo mongodump --out /backup

# Backup volumes Docker
docker run --rm -v lakehouse-project_postgres-data:/data -v $(pwd):/backup busybox tar czf /backup/postgres-backup.tar.gz /data
```

### Limpeza de Recursos

```bash
# Remover containers parados
docker-compose down

# Remover volumes (ATENÃ‡ÃƒO: perde dados)
docker-compose down -v

# Limpar imagens nÃ£o usadas
docker image prune -a

# Limpar tudo do Docker
docker system prune -a --volumes
```

### AtualizaÃ§Ã£o de ServiÃ§os

```bash
# Atualizar imagem especÃ­fica
docker-compose pull <service-name>
docker-compose up -d <service-name>

# Rebuild apÃ³s mudanÃ§as no Dockerfile
docker-compose build --no-cache airflow-webserver
docker-compose up -d airflow-webserver

# Atualizar todos os serviÃ§os
docker-compose pull
docker-compose up -d --build
```

### Logs e Debugging

```bash
# Todos os logs
docker-compose logs

# Logs de serviÃ§o especÃ­fico
docker-compose logs -f <service-name>

# Logs com timestamp
docker-compose logs -f --timestamps <service-name>

# Ãšltimas 100 linhas
docker-compose logs --tail=100 <service-name>

# Logs de mÃºltiplos serviÃ§os
docker-compose logs -f airflow-webserver airflow-scheduler
```

### Escalar Workers

```bash
# Adicionar mais workers (editar docker-compose.yml)
# Duplicar bloco airflow-worker-bronze-2 com novo nome

# Aplicar mudanÃ§as
docker-compose up -d --scale airflow-worker-bronze-2=3
```

### Monitorar Recursos

```bash
# Uso em tempo real
docker stats

# EspaÃ§o em disco dos volumes
docker system df -v

# Inspecionar container
docker inspect <container-name>
```

---

## ğŸ“ Notas Importantes

- **Senhas padrÃ£o**: Altere as credenciais em produÃ§Ã£o
- **Volumes persistentes**: Dados sobrevivem a `docker-compose down`
- **Recursos**: Ajuste limites no `docker-compose.yml` se necessÃ¡rio
- **Rede**: Todos os serviÃ§os na rede `lakehouse-net`
- **Healthchecks**: PostgreSQL tem healthcheck configurado

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

---

## ğŸ‘¥ Autores

- **BehindTheBush** - [GitHub](https://github.com/BehindTheBush)

---

## ğŸ™ Agradecimentos

- Apache Airflow Community
- Confluent Platform (Kafka)
- MinIO Team
- Prometheus & Grafana Labs
- Docker & Docker Compose

---

**ğŸš€ Happy Data Engineering!**
